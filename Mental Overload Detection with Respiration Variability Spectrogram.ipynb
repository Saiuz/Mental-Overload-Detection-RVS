{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = loadmat(\"respiratory_variability_spectrogram__dataset.mat\")\n",
    "participants_indices = data[\"subarray\"].ravel()\n",
    "participants = np.unique(participants_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data[\"train_x\"]\n",
    "x = np.swapaxes(x, 1, 2)\n",
    "x = np.swapaxes(x, 0, 1)\n",
    "x = x.reshape(-1, 120, 120, 1)\n",
    "x = tf.Session().run(tf.image.resize_images(x, [28,28]))\n",
    "y = data[\"train_y_binary\"]\n",
    "y = np.hstack([y[0].reshape(-1, 1), y[1].reshape(-1, 1)]) # 1 - No Stress and 2 - Stress\n",
    "\n",
    "for p in participants:\n",
    "    indices = np.where(participants_indices == p)\n",
    "    np.save(\"\".join([\"x_\",str(p)]), x[indices]) \n",
    "    np.save(\"\".join([\"y_\",str(p)]), y[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D,  MaxPooling2D\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_dim = 28\n",
    "n_channels = 1\n",
    "n_classes = 2\n",
    "l2_rate = 0.0001\n",
    "learning_rate = 3e-4\n",
    "epochs = 5\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517431192661   0.34900990099   1.0\n",
      "0.908088235294   0.83164983165   1.0\n",
      "1.0   1.0   1.0\n",
      "0.715189873418   0.556650246305   1.0\n",
      "0.979005524862   1.0   0.958874458874\n",
      "0.877486910995   1.0   0.78171641791\n",
      "0.962962962963   0.928571428571   1.0\n",
      "0.993736951983   1.0   0.98755186722\n",
      "Avg F-Score:  0.8692  Avg Precision:  0.8332  Avg Recall:  0.966\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = [], [], []\n",
    "cfm = []\n",
    "for p in range(len(participants)):\n",
    "    val_X = np.load(\"\".join([\"x_\",str(participants[p]), \".npy\"]))\n",
    "    val_Y = np.load(\"\".join([\"y_\",str(participants[p]), \".npy\"]))\n",
    "    training_participants = np.delete(participants, p)\n",
    "    tr_X = np.empty((0, n_dim, n_dim, n_channels))\n",
    "    tr_Y = np.empty((0, n_classes))\n",
    "    for p in training_participants:\n",
    "        tr_X = np.vstack([tr_X, np.load(\"\".join([\"x_\",str(p), \".npy\"]))])\n",
    "        tr_Y = np.vstack([tr_Y, np.load(\"\".join([\"y_\",str(p), \".npy\"]))])\n",
    "    \n",
    "    K.clear_session()\n",
    "    X = Input(shape=(n_dim, n_dim, n_channels), name = \"input\")\n",
    "    x = Conv2D(12, kernel_size = 4, \n",
    "              strides = 1, \n",
    "              activation = \"relu\", \n",
    "              kernel_regularizer=l2(l2_rate),\n",
    "              name = \"conv_1\")(X)\n",
    "    x = MaxPooling2D(pool_size = 2)(x)\n",
    "    x = Conv2D(24, kernel_size = 4, \n",
    "              strides = 1, \n",
    "              activation = \"relu\", \n",
    "              kernel_regularizer=l2(l2_rate),\n",
    "              name = \"conv_2\")(x)\n",
    "    x = MaxPooling2D(pool_size = 2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation = \"relu\")(x)\n",
    "    predictions = Dense(2, activation = \"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs = X, outputs = predictions)\n",
    "    model.compile(optimizer = Adam(lr = learning_rate), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    model.fit(tr_X, tr_Y, epochs = epochs, batch_size = batch_size, shuffle = True, verbose = 0)\n",
    "    \n",
    "    val_predictions = model.predict(val_X)\n",
    "    p, r, f, _ = precision_recall_fscore_support(np.argmax(val_Y, 1), np.argmax(val_predictions, 1), average = \"binary\")\n",
    "    fscore.append(f)\n",
    "    precision.append(p)\n",
    "    recall.append(r)\n",
    "    cfm.append(confusion_matrix(np.argmax(val_Y, 1), np.argmax(val_predictions, 1)))\n",
    "    print(f, \" \", p, \" \", r)\n",
    "    \n",
    "print(\"Avg F-Score: \", round(np.mean(fscore), 4), \" Avg Precision: \", round(np.mean(precision), 4),\n",
    "     \" Avg Recall: \", round(np.mean(recall), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
